"""
Aplikacja Streamlit do analizy s≈Ç√≥w kluczowych.
"""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
import os
import sys
import time
from typing import List, Dict, Any, Optional, Tuple

# Dodaj katalog projektu do ≈õcie≈ºki
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Importy z projektu
from utils.data_loader import load_and_prepare_data, save_analysis, load_analysis
from models.embeddings import EmbeddingGenerator
from models.clustering import KeywordClusterer
from models.analyzer import KeywordAnalyzer
from utils.visualizer import KeywordVisualizer
from config.config import DATA_DIR, OUTPUT_DIR

# Konfiguracja strony
st.set_page_config(
    page_title="Analizator S≈Ç√≥w Kluczowych",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Tytu≈Ç aplikacji
st.title("Analizator S≈Ç√≥w Kluczowych")
st.markdown("**Narzƒôdzie do klastrowania i analizy s≈Ç√≥w kluczowych z wykorzystaniem AI**")

# Panel boczny
st.sidebar.header("Ustawienia")

# Sekcja importu/eksportu analizy
st.sidebar.subheader("Import/Eksport analizy")

# Przycisk do zapisania analizy - widoczny zawsze
if st.sidebar.button("üíæ Zapisz analizƒô", type="secondary"):
    # Sprawd≈∫ czy mamy dane do zapisania
    if 'clustered_df' in st.session_state:
        # Zbierz wszystkie dane z sesji do zapisania
        analysis_data = {
            'keywords_df': st.session_state.get('keywords_df'),
            'stats': st.session_state.get('stats'),
            'df_with_embeddings': st.session_state.get('df_with_embeddings'),
            'reduced_embeddings': st.session_state.get('reduced_embeddings'),
            'clustered_df': st.session_state.get('clustered_df'),
            'cluster_names': st.session_state.get('cluster_names'),
            'cluster_analyses': st.session_state.get('cluster_analyses'),
            'plots': st.session_state.get('plots'),
            'intent_plot': st.session_state.get('intent_plot'),
            'cluster_map': st.session_state.get('cluster_map')
        }
        
        # Zapisz analizƒô
        save_path = save_analysis(analysis_data)
        st.sidebar.success(f"Analiza zapisana: {os.path.basename(save_path)}")
    else:
        # Komunikat je≈õli nie ma danych do zapisania
        st.sidebar.error("Brak danych do zapisania. Wykonaj analizƒô przed zapisaniem.")

# Wczytywanie zapisanej analizy
import_file = st.sidebar.file_uploader("Wczytaj zapisanƒÖ analizƒô (.pkl)", type=["pkl"])
if import_file:
    try:
        # Zapisz plik tymczasowo
        temp_path = os.path.join(DATA_DIR, import_file.name)
        with open(temp_path, "wb") as f:
            f.write(import_file.getbuffer())
        
        # Wczytaj analizƒô
        loaded_data = load_analysis(temp_path)
        
        # Przywr√≥ƒá dane do sesji
        for key, value in loaded_data.items():
            st.session_state[key] = value
        
        st.session_state.analysis_completed = True
        st.session_state.file_imported = True
        st.session_state.imported_file_name = import_file.name
        
        st.sidebar.success(f"Analiza wczytana: {import_file.name}")
        st.rerun()  # Od≈õwie≈º aplikacjƒô aby zaktualizowaƒá wy≈õwietlane dane
        
    except Exception as e:
        st.sidebar.error(f"B≈ÇƒÖd podczas wczytywania analizy: {e}")

# Oddzielamy sekcje w bocznym panelu
st.sidebar.markdown("---")
st.sidebar.subheader("Nowa analiza")

# Funkcja do wczytywania i przetwarzania danych
def process_keywords(file_path):
    """
    Przetwarza s≈Çowa kluczowe z pliku.
    
    Args:
        file_path: ≈öcie≈ºka do pliku z danymi
        
    Returns:
        Tuple zawierajƒÖcy wyniki analizy i wizualizacje
    """
    # Inicjalizacja pask√≥w postƒôpu
    progress_col, status_col = st.columns([3, 2])
    overall_progress_bar = progress_col.progress(0)
    overall_status = progress_col.empty()
    
    step_progress_bar = progress_col.progress(0)
    step_status = progress_col.empty()
    
    current_step_container = status_col.empty()
    overall_status_container = status_col.empty()
    
    # Funkcja callback do aktualizacji pask√≥w postƒôpu
    def update_progress(overall_progress, step_progress, overall_text, step_text, step_name):
        overall_progress_bar.progress(overall_progress)
        overall_status.text(overall_text)
        step_progress_bar.progress(step_progress)
        step_status.text(step_text)
        current_step_container.markdown(f"### Obecny krok: {step_name}")
    
    # Krok 1: Wczytaj i przygotuj dane (10%)
    update_progress(0.0, 0.0, "Inicjalizacja...", "Wczytywanie pliku...", "Przetwarzanie danych")
    
    df, stats = load_and_prepare_data(file_path)
    st.session_state.keywords_df = df
    st.session_state.stats = stats
    
    update_progress(0.1, 1.0, "Przetwarzanie danych zako≈Ñczone", "Plik wczytany", "Przetwarzanie danych")
    
    # Krok 2: Generuj embeddingi (10% - 30%)
    embedding_generator = EmbeddingGenerator()
    
    def embedding_callback(progress, status):
        update_progress(0.1 + 0.2 * progress, progress, 
                       "Generowanie embeding√≥w...", 
                       status, 
                       "Generowanie embeding√≥w")
    
    df_with_embeddings = embedding_generator.process_keywords_dataframe(df, progress_callback=embedding_callback)
    st.session_state.df_with_embeddings = df_with_embeddings
    
    # Krok 3: Klastruj s≈Çowa kluczowe (30% - 50%)
    clusterer = KeywordClusterer()
    
    def clustering_callback(progress, status):
        update_progress(0.3 + 0.2 * progress, progress,
                       "Klastrowanie s≈Ç√≥w kluczowych...",
                       status,
                       "Klastrowanie")
    
    clustered_df = clusterer.process_keywords_dataframe(df_with_embeddings, progress_callback=clustering_callback)
    st.session_state.reduced_embeddings = clusterer.reduced_embeddings
    st.session_state.clustered_df = clustered_df
    
    # Krok 4: Nazwij klastry (50% - 65%)
    analyzer = KeywordAnalyzer()
    
    def naming_callback(progress, status):
        update_progress(0.5 + 0.15 * progress, progress,
                       "Nazywanie klastr√≥w...",
                       status,
                       "Nazywanie klastr√≥w")
    
    cluster_names = analyzer.name_clusters(clustered_df, progress_callback=naming_callback)
    st.session_state.cluster_names = cluster_names
    
    # Krok 5: Analizuj klastry (65% - 85%)
    def analysis_callback(progress, status):
        update_progress(0.65 + 0.2 * progress, progress,
                       "Analizowanie klastr√≥w...",
                       status,
                       "Analiza klastr√≥w")
    
    cluster_analyses = analyzer.process_all_clusters(clustered_df, cluster_names, progress_callback=analysis_callback)
    st.session_state.cluster_analyses = cluster_analyses
    
    # Krok 6: Tw√≥rz wizualizacje (85% - 100%)
    update_progress(0.85, 0.0, "Tworzenie wizualizacji...", "Przygotowywanie wykres√≥w...", "Wizualizacja")
    
    visualizer = KeywordVisualizer()
    
    # Podsumowanie klastr√≥w
    update_progress(0.90, 0.3, "Tworzenie wizualizacji...", "Wykres podsumowania klastr√≥w...", "Wizualizacja")
    plots = visualizer.plot_cluster_summary(cluster_analyses)
    st.session_state.plots = plots
    
    # Rozk≈Çad intencji - ZMIANA: przekazanie stats zamiast DataFrame
    update_progress(0.93, 0.6, "Tworzenie wizualizacji...", "Wykres rozk≈Çadu intencji...", "Wizualizacja")
    intent_plot = visualizer.plot_intent_distribution(stats)
    st.session_state.intent_plot = intent_plot
    
    # Mapa klastr√≥w
    update_progress(0.96, 0.9, "Tworzenie wizualizacji...", "Mapa klastr√≥w...", "Wizualizacja")
    cluster_map = visualizer.plot_cluster_map(clustered_df, cluster_names, clusterer.reduced_embeddings)
    st.session_state.cluster_map = cluster_map
    
    # Zako≈Ñczenie
    update_progress(1.0, 1.0, "Analiza zako≈Ñczona", "Wszystkie wizualizacje gotowe", "Zako≈Ñczono")
    time.sleep(0.5)  # Chwilowa pauza przed wy≈õwietleniem wynik√≥w
    
    st.success("Analiza zako≈Ñczona!")
    
    # Usu≈Ñ paski postƒôpu
    progress_col.empty()
    status_col.empty()

# Wczytywanie pliku
upload_file = st.sidebar.file_uploader("Wczytaj plik CSV/Excel z Ahrefs", type=["csv", "xlsx", "xls"])

if upload_file:
    # Zapisz plik tymczasowo
    file_path = os.path.join(DATA_DIR, upload_file.name)
    with open(file_path, "wb") as f:
        f.write(upload_file.getbuffer())
    
    # Zapisz informacjƒô o wczytanym pliku w sesji
    st.session_state.file_uploaded = True
    st.session_state.file_path = file_path
    st.session_state.file_name = upload_file.name
    
    # Wy≈õwietl informacjƒô o wczytanym pliku
    st.sidebar.success(f"Plik wczytany: {upload_file.name}")
    
    # Przycisk do uruchomienia analizy
    if st.sidebar.button("üöÄ Uruchom analizƒô", type="primary"):
        # Wyczy≈õƒá poprzednie wyniki je≈õli istniejƒÖ
        keys_to_clear = ['clustered_df', 'cluster_analyses', 'plots', 'intent_plot', 'cluster_map', 
                         'keywords_df', 'stats', 'df_with_embeddings', 'reduced_embeddings', 'cluster_names']
        for key in keys_to_clear:
            if key in st.session_state:
                del st.session_state[key]
        
        # Uruchom analizƒô
        process_keywords(file_path)
        st.session_state.analysis_completed = True
    
    # Przycisk do ponownego przetworzenia (je≈õli analiza by≈Ça ju≈º wykonana)
    if 'analysis_completed' in st.session_state and st.session_state.analysis_completed:
        if st.sidebar.button("‚Üª Analizuj ponownie"):
            # Resetujemy sesjƒô
            for key in list(st.session_state.keys()):
                if key not in ['file_uploaded', 'file_path', 'file_name']:
                    del st.session_state[key]
            process_keywords(file_path)
            st.session_state.analysis_completed = True

# Wy≈õwietlanie wynik√≥w
if 'clustered_df' in st.session_state:
    # Podstawowe statystyki
    st.header("PrzeglƒÖd danych")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Liczba s≈Ç√≥w kluczowych", st.session_state.stats['total_keywords'])
    
    with col2:
        st.metric("≈ÅƒÖczny wolumen wyszukiwa≈Ñ", st.session_state.stats['total_volume'])
    
    with col3:
        st.metric("≈örednia trudno≈õƒá (KD)", f"{st.session_state.stats['avg_difficulty']:.2f}")
    
    # Rozk≈Çad intencji
    st.header("Rozk≈Çad intencji wyszukiwania")
    st.plotly_chart(st.session_state.intent_plot, use_container_width=True)
    
    # Mapa klastr√≥w
    st.header("Mapa klastr√≥w s≈Ç√≥w kluczowych")
    st.plotly_chart(st.session_state.cluster_map, use_container_width=True)
    
    # Wizualizacje klastr√≥w
    st.header("Podsumowanie klastr√≥w")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Wolumen wyszukiwa≈Ñ wed≈Çug klastr√≥w")
        st.plotly_chart(st.session_state.plots['volume'], use_container_width=True)
    
    with col2:
        st.subheader("Liczba s≈Ç√≥w kluczowych wed≈Çug klastr√≥w")
        st.plotly_chart(st.session_state.plots['count'], use_container_width=True)
    
    st.subheader("Trudno≈õƒá vs. wolumen vs. liczba s≈Ç√≥w kluczowych")
    st.plotly_chart(st.session_state.plots['scatter'], use_container_width=True)
    
    st.subheader("Rozk≈Çad priorytet√≥w klastr√≥w")
    st.plotly_chart(st.session_state.plots['priority'], use_container_width=True)
    
    # Szczeg√≥≈Çowe wyniki dla ka≈ºdego klastra
    st.header("Szczeg√≥≈Çowa analiza klastr√≥w")
    
    for cluster_analysis in st.session_state.cluster_analyses:
        # Okre≈õlenie koloru dla priorytetu
        if cluster_analysis['priority_level'] == 'Wysoki':
            priority_color = "#ff7043"  # pomara≈Ñczowy
        elif cluster_analysis['priority_level'] == '≈öredni':
            priority_color = "#ffa726"  # ≈º√≥≈Çty
        else:
            priority_color = "#66bb6a"  # zielony
        
        # Tworzenie nag≈Ç√≥wka z kolorowym znacznikiem priorytetu
        st.markdown(
            f"""
            <h3 style="margin-bottom: 0px;">
                {cluster_analysis['cluster_name']} 
                <span style="color: {priority_color}; font-size: 0.8em;">
                    [{cluster_analysis['priority_level']} priorytet]
                </span>
            </h3>
            """, 
            unsafe_allow_html=True
        )
        
        # Metryki klastra
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Liczba s≈Ç√≥w kluczowych", cluster_analysis['keywords_count'])
        
        with col2:
            st.metric("≈ÅƒÖczny wolumen", cluster_analysis['total_volume'])
        
        with col3:
            st.metric("≈örednia trudno≈õƒá", f"{cluster_analysis['avg_difficulty']:.2f}")
        
        with col4:
            st.metric("≈öredni CPC", f"${cluster_analysis['avg_cpc']:.2f}")
        
        # Wnioski i rekomendacje
        st.markdown("**Wnioski:**")
        st.write(cluster_analysis['insights'])
        
        st.markdown("**Rekomendacje dla tre≈õci:**")
        st.write(cluster_analysis['content_strategy'])
        
        # S≈Çowa kluczowe w klastrze
        with st.expander("Zobacz s≈Çowa kluczowe w tym klastrze"):
            cluster_id = cluster_analysis['cluster_id']
            cluster_keywords = st.session_state.clustered_df[st.session_state.clustered_df['cluster'] == cluster_id]
            cluster_keywords = cluster_keywords.sort_values(by='volume', ascending=False)
            
            # Sprawdzenie jakie kolumny intencji sƒÖ dostƒôpne
            intent_columns = ['branded', 'local', 'navigational', 'informational', 'commercial', 'transactional']
            available_intent_columns = [col for col in intent_columns if col in cluster_keywords.columns]
            display_columns = ['keyword', 'volume', 'difficulty', 'cpc']
            
            # Dodaj kolumny intencji, je≈õli sƒÖ dostƒôpne
            if available_intent_columns:
                display_columns.extend(available_intent_columns)
            elif 'intent' in cluster_keywords.columns:
                display_columns.append('intent')
                
            st.dataframe(cluster_keywords[display_columns])
        
        st.markdown("---")
    
    # Opcja eksportu wynik√≥w
    st.header("Eksport wynik√≥w")
    
    # Eksport oryginalnych danych z klastrami
    if st.button("Eksportuj wszystkie s≈Çowa kluczowe z klastrami"):
        # Przygotuj dane do eksportu
        export_df = st.session_state.clustered_df.copy()
        
        # Dodaj nazwy klastr√≥w
        export_df['cluster_name'] = export_df['cluster'].map(
            lambda c: st.session_state.cluster_names.get(c, f"Cluster {c}") if c != -1 else "Outliers"
        )
        
        # Usu≈Ñ kolumny z embedingami i inne du≈ºe obiekty przed zapisem
        columns_to_drop = []
        if 'embedding' in export_df.columns:
            columns_to_drop.append('embedding')
        
        # Przekszta≈Çƒá listƒô intencji na string przed zapisem
        if 'intent_list' in export_df.columns:
            export_df['intent_list'] = export_df['intent_list'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)
            
        if columns_to_drop:
            export_df = export_df.drop(columns=columns_to_drop)
        
        # Zapisz do pliku
        export_path = os.path.join(OUTPUT_DIR, "keywords_with_clusters.csv")
        export_df.to_csv(export_path, index=False)
        
        # Link do pobrania
        st.markdown(f"Plik zosta≈Ç zapisany w: `{export_path}`")
    
    # Eksport analizy klastr√≥w
    if st.button("Eksportuj analizƒô klastr√≥w"):
        # Przygotuj dane do eksportu
        export_df = pd.DataFrame(st.session_state.cluster_analyses)
        
        # Zapisz do pliku
        export_path = os.path.join(OUTPUT_DIR, "cluster_analysis.csv")
        export_df.to_csv(export_path, index=False)
        
        # Link do pobrania
        st.markdown(f"Plik zosta≈Ç zapisany w: `{export_path}`")

else:
    # Instrukcje dla u≈ºytkownika
    if 'file_imported' in st.session_state and st.session_state.file_imported:
        st.info(f"Wczytano zapisanƒÖ analizƒô: {st.session_state.imported_file_name}")
    else:
        st.info("Wczytaj plik CSV lub Excel z eksportu Ahrefs, aby rozpoczƒÖƒá analizƒô, lub zaimportuj zapisanƒÖ analizƒô.")
    
    # Przyk≈Çadowa struktura danych
    st.markdown("""
    ### Oczekiwana struktura danych
    
    Plik powinien zawieraƒá co najmniej nastƒôpujƒÖce kolumny:
    - `keyword` - fraza kluczowa
    - `volume` - miesiƒôczny wolumen wyszukiwa≈Ñ
    - `difficulty` / `kd` - trudno≈õƒá s≈Çowa kluczowego
    - `intent` - intencja wyszukiwania (informational, commercial, transactional, navigational)
    - `cpc` - koszt klikniƒôcia
    
    Dodatkowo, dla rozk≈Çadu intencji, aplikacja obs≈Çuguje kolumny:
    - `branded` - intencja brandowa (True/False)
    - `local` - intencja lokalna (True/False)
    - `navigational` - intencja nawigacyjna (True/False)
    - `informational` - intencja informacyjna (True/False)
    - `commercial` - intencja komercyjna (True/False)
    - `transactional` - intencja transakcyjna (True/False)
    
    Nazwy kolumn mogƒÖ nieznacznie siƒô r√≥≈ºniƒá - aplikacja spr√≥buje je zmapowaƒá automatycznie.
    """)